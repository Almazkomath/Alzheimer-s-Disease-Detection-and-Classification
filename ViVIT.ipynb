{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e89af2-55bc-46b9-b8ce-e574a3a025a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Path & data settings\n",
    "DATA_DIR = r\"C:\\Users\\Alma\\Desktop\\Data\\sliced_data\"\n",
    "AXES = ['X', 'Y', 'Z']\n",
    "METRICS = ['FA', 'MD', 'RD', 'AD']\n",
    "CLASSES = ['MCI', 'NC']\n",
    "\n",
    "# Image and sequence shape settings\n",
    "NUM_FRAMES = 100    # slices per sequence\n",
    "IMG_SIZE = 128      # target size of images\n",
    "CHANNELS = len(METRICS)  # 4 (FA, MD, RD, AD)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f63941-a246-45fb-ada3-f56561893a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_slices(subject_path, axis):\n",
    "    \"\"\"\n",
    "    Load slices for a single subject along a specific axis.\n",
    "    Returns a 4D array: (frames, height, width, channels)\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for slice_idx in range(NUM_FRAMES):\n",
    "        slice_imgs = []\n",
    "        for metric in METRICS:\n",
    "            folder = f\"Sliced_{axis}_{metric}\"\n",
    "            slice_filename = f\"slice_{slice_idx:03d}.png\"\n",
    "            slice_path = os.path.join(subject_path, folder, slice_filename)\n",
    "\n",
    "            if not os.path.exists(slice_path):\n",
    "                print(f\"Warning: Missing slice {slice_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            img = Image.open(slice_path).convert('L')  # grayscale\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE))     # resize image\n",
    "            img = np.array(img) / 255.0                # normalize [0, 1]\n",
    "\n",
    "            slice_imgs.append(img)\n",
    "\n",
    "        if len(slice_imgs) == len(METRICS):\n",
    "            # Stack all metrics as channels: (H, W, 4)\n",
    "            slice_stack = np.stack(slice_imgs, axis=-1)\n",
    "            frames.append(slice_stack)\n",
    "        else:\n",
    "            print(f\"Warning: Incomplete metrics at slice {slice_idx} in {subject_path} for axis {axis}\")\n",
    "\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358b4f19-87d3-432e-81cb-1889a107a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "AXES = ['X', 'Y', 'Z']\n",
    "METRICS = ['FA', 'MD', 'RD', 'AD']\n",
    "SLICE_COUNT = 100   # Number of slices per axis\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_CLASSES = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48dce30c-b95c-464f-b043-352dca467739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_subject_slices(subject_path):\n",
    "    \"\"\"Load slices for one subject.\"\"\"\n",
    "    subject_data = []\n",
    "    axes_found = True  # We use this to skip subjects with missing data\n",
    "\n",
    "    for axis in AXES:\n",
    "        axis_slices = []\n",
    "        for slice_idx in range(SLICE_COUNT):\n",
    "            metrics_slices = []\n",
    "            for metric in METRICS:\n",
    "                # FIXED path construction\n",
    "                metric_folder = os.path.join(subject_path, f\"Sliced_{axis}_{metric}\")\n",
    "\n",
    "                if not os.path.exists(metric_folder):\n",
    "                    print(f\"‚ùå Missing folder: {metric_folder}\")\n",
    "                    axes_found = False\n",
    "                    break\n",
    "\n",
    "                slice_filename = f\"slice_{slice_idx:03d}.png\"\n",
    "                slice_path = os.path.join(metric_folder, slice_filename)\n",
    "\n",
    "                if not os.path.exists(slice_path):\n",
    "                    print(f\"‚ùå Missing slice {slice_path}\")\n",
    "                    axes_found = False\n",
    "                    break\n",
    "\n",
    "                # Load and preprocess image\n",
    "                img = Image.open(slice_path).convert('L')  # grayscale\n",
    "                img = img.resize(IMG_SIZE)\n",
    "                img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "                metrics_slices.append(img_array)\n",
    "\n",
    "            if not axes_found:\n",
    "                break\n",
    "\n",
    "            # Stack FA, MD, RD, AD channels into (224, 224, 4)\n",
    "            axis_slices.append(np.stack(metrics_slices, axis=-1))\n",
    "\n",
    "        if not axes_found:\n",
    "            print(f\"‚ö†Ô∏è Skipping subject {subject_path} due to missing data on axis {axis}\")\n",
    "            return None\n",
    "\n",
    "        # Stack 100 slices along time axis (100, 224, 224, 4)\n",
    "        subject_data.append(np.stack(axis_slices))\n",
    "\n",
    "    # Final shape (3 axes, 100 slices, 224, 224, 4 metrics)\n",
    "    return np.stack(subject_data)\n",
    "\n",
    "def build_dataset(data_dir):\n",
    "    \"\"\"Iterate over folders and build X and y datasets.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Get correct class folders (MCI and NC ONLY)\n",
    "    class_names = sorted([\n",
    "        cls for cls in os.listdir(data_dir)\n",
    "        if os.path.isdir(os.path.join(data_dir, cls)) and cls in ['MCI', 'NC']\n",
    "    ])\n",
    "\n",
    "    print(\"‚úÖ Classes found:\", class_names)\n",
    "\n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(data_dir, class_name)\n",
    "        subject_folders = [\n",
    "            sf for sf in os.listdir(class_folder)\n",
    "            if os.path.isdir(os.path.join(class_folder, sf))\n",
    "        ]\n",
    "\n",
    "        print(f\"\\nüîé Processing class '{class_name}' with {len(subject_folders)} subjects\")\n",
    "\n",
    "        for subject_id in tqdm(subject_folders):\n",
    "            subject_path = os.path.join(class_folder, subject_id)\n",
    "\n",
    "            subject_slices = load_subject_slices(subject_path)\n",
    "\n",
    "            if subject_slices is not None:\n",
    "                X.append(subject_slices)\n",
    "                y.append(label_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(f\"\\n‚úÖ Dataset loaded. X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1143cdb3-603c-4349-ba3e-e70d6ef5fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classes found: ['MCI', 'NC']\n",
      "\n",
      "üîé Processing class 'MCI' with 101 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [38:22<00:00, 22.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Processing class 'NC' with 101 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                     | 55/101 [26:01<21:45, 28.39s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 230. MiB for an array with shape (3, 100, 224, 224, 4) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Split into train and validation sets\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      5\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
      "Cell \u001b[1;32mIn[23], line 74\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject_id \u001b[38;5;129;01min\u001b[39;00m tqdm(subject_folders):\n\u001b[0;32m     72\u001b[0m     subject_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_folder, subject_id)\n\u001b[1;32m---> 74\u001b[0m     subject_slices \u001b[38;5;241m=\u001b[39m \u001b[43mload_subject_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject_slices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(subject_slices)\n",
      "Cell \u001b[1;32mIn[23], line 47\u001b[0m, in \u001b[0;36mload_subject_slices\u001b[1;34m(subject_path)\u001b[0m\n\u001b[0;32m     44\u001b[0m     subject_data\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mstack(axis_slices))\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Final shape (3 axes, 100 slices, 224, 224, 4 metrics)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[0;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 230. MiB for an array with shape (3, 100, 224, 224, 4) and data type float32"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(DATA_DIR)\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set shape: {X_train.shape}, Validation set shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ddc88-60ce-4155-849d-692739b9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vivit_model(input_shape, num_classes=2, projection_dim=64, transformer_layers=4, num_heads=4):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Tubelet embedding (3D patches)\n",
    "    patch_size = (10, 16, 16)  # Time, Height, Width\n",
    "    num_patches = (\n",
    "        input_shape[0] // patch_size[0],\n",
    "        input_shape[1] // patch_size[1],\n",
    "        input_shape[2] // patch_size[2]\n",
    "    )\n",
    "    \n",
    "    x = layers.Conv3D(\n",
    "        filters=projection_dim,\n",
    "        kernel_size=patch_size,\n",
    "        strides=patch_size,\n",
    "        padding='valid'\n",
    "    )(inputs)\n",
    "    \n",
    "    x = layers.Reshape((num_patches[0] * num_patches[1] * num_patches[2], projection_dim))(x)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(start=0, limit=x.shape[1], delta=1)\n",
    "    pos_encoding = layers.Embedding(input_dim=x.shape[1], output_dim=projection_dim)(positions)\n",
    "    x = x + pos_encoding\n",
    "\n",
    "    # Transformer Encoder blocks\n",
    "    for _ in range(transformer_layers):\n",
    "        # LayerNorm\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        \n",
    "        # Multi-head Self Attention\n",
    "        attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(x1, x1)\n",
    "        x2 = layers.Add()([attention, x])\n",
    "\n",
    "        # MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        mlp = layers.Dense(projection_dim * 4, activation='gelu')(x3)\n",
    "        mlp = layers.Dense(projection_dim)(mlp)\n",
    "        x = layers.Add()([x2, mlp])\n",
    "\n",
    "    # Classification Head\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0eb6c-03c3-4e13-baa6-1064255f2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_vivit_classifier()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540dd1e-9e2f-4a55-8bd8-1ef85258ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val_cat)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Plot accuracy curves\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
